{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment-1.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPCzMBz0EvA54jibwnfS8qL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rishika-p/NLP-assignments/blob/main/Assignment_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zFJWoD3Rd-Od",
        "outputId": "61234432-8c7f-41c2-9850-454bcc43b448"
      },
      "source": [
        "data1= \"\"\"Are  you  fascinated  by  the  amount  of  text  data  available  on  the  internet?  Are  you  looking  for  ways  to  work  with  this  text  data  but  aren’t  sure  where  to  begin?  Machines, after all, recognize numbers, not the letters of our language. And that can  be a tricky landscape to navigate in machine learning. \"\"\"\n",
        "\n",
        "#1.Split the above paragraph into sentences\n",
        "\n",
        "def SIS(data1):\n",
        "  res = []\n",
        "  sentences = data1.split(\"?\")\n",
        "  for sentence in sentences:\n",
        "    res.extend(sentence.split(\".\"))\n",
        "  return res\n",
        "sent_in_data = SIS(data1)\n",
        "print(sent_in_data)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Are  you  fascinated  by  the  amount  of  text  data  available  on  the  internet', '  Are  you  looking  for  ways  to  work  with  this  text  data  but  aren’t  sure  where  to  begin', '  Machines, after all, recognize numbers, not the letters of our language', ' And that can  be a tricky landscape to navigate in machine learning', ' ']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-mtlwf0Wgsh7",
        "outputId": "9b19d242-5632-4972-972a-b132142e084a"
      },
      "source": [
        "#2.Split the above paragraph into words\n",
        "\n",
        "words = data1.split()\n",
        "print(words)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Are', 'you', 'fascinated', 'by', 'the', 'amount', 'of', 'text', 'data', 'available', 'on', 'the', 'internet?', 'Are', 'you', 'looking', 'for', 'ways', 'to', 'work', 'with', 'this', 'text', 'data', 'but', 'aren’t', 'sure', 'where', 'to', 'begin?', 'Machines,', 'after', 'all,', 'recognize', 'numbers,', 'not', 'the', 'letters', 'of', 'our', 'language.', 'And', 'that', 'can', 'be', 'a', 'tricky', 'landscape', 'to', 'navigate', 'in', 'machine', 'learning.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oJqB86TNg06S",
        "outputId": "530cd0ba-1e5e-478d-acf2-510be79bbbd9"
      },
      "source": [
        "#3.Find stem and lemma words for the given words?\n",
        "#stem\n",
        "\n",
        "from nltk.stem import PorterStemmer\n",
        "words1= [\"cats\", \"trouble\", \"troubling\", \"troubled\", \"having\", \"Corriendo\", \"at\", \"was\"]\n",
        "ps =PorterStemmer()\n",
        "for a in words1:\n",
        "    root_Word=ps.stem(a)\n",
        "    print(\"Stem for {} is {}\".format(a, root_Word))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stem for cats is cat\n",
            "Stem for trouble is troubl\n",
            "Stem for troubling is troubl\n",
            "Stem for troubled is troubl\n",
            "Stem for having is have\n",
            "Stem for Corriendo is corriendo\n",
            "Stem for at is at\n",
            "Stem for was is wa\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8NOwCjP4htNy",
        "outputId": "7d911a55-6978-41dd-ce60-6c3d5e395abf"
      },
      "source": [
        "#lemma\n",
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "from nltk.stem import \tWordNetLemmatizer\n",
        "wordnet_lemmatizer = WordNetLemmatizer()\n",
        "for a in words1:\n",
        "  print(\"Lemma for {} is {}\".format(a, wordnet_lemmatizer.lemmatize(a)))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "Lemma for cats is cat\n",
            "Lemma for trouble is trouble\n",
            "Lemma for troubling is troubling\n",
            "Lemma for troubled is troubled\n",
            "Lemma for having is having\n",
            "Lemma for Corriendo is Corriendo\n",
            "Lemma for at is at\n",
            "Lemma for was is wa\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AcMIRxCrh6Y_",
        "outputId": "54bc9afa-e9cd-41be-d129-a6e54e55ddbf"
      },
      "source": [
        "#4. Find stop words from the given paragraph?\n",
        "\n",
        "data2=\"\" \"The NLTK library  is  one  of  the  oldest  and  most  commonly  used  Python  libraries  for  Natural Language Processing. NLTK supports stop word removal, and you can find the list  of stop words in the  corpus  module. To remove stop words from a sentence, you can divide  your text into words and then remove the word if it exits in the list of stop words provided  by NLTK.\"\"\"\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "words = word_tokenize(data2)\n",
        "words = [word.lower() for word in words] \n",
        "step_Words = []\n",
        "for word in words:\n",
        "  if word in set(stopwords.words(\"english\")):\n",
        "    step_Words.append(word)\n",
        "print(step_Words)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "['the', 'is', 'of', 'the', 'and', 'most', 'for', 'and', 'you', 'can', 'the', 'of', 'in', 'the', 'to', 'from', 'a', 'you', 'can', 'your', 'into', 'and', 'then', 'the', 'if', 'it', 'in', 'the', 'of', 'by']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ongvKBAAigQO",
        "outputId": "fd0f1449-e24f-4ca4-e3fe-0158475973ce"
      },
      "source": [
        "#5. From the above paragraph print frequency of each word using NLTK?\n",
        "\n",
        "output = {}\n",
        "for word in words:\n",
        "  output[word] = output.get(word, 0) + 1\n",
        "print(output)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'the': 6, 'nltk': 3, 'library': 1, 'is': 1, 'one': 1, 'of': 3, 'oldest': 1, 'and': 3, 'most': 1, 'commonly': 1, 'used': 1, 'python': 1, 'libraries': 1, 'for': 1, 'natural': 1, 'language': 1, 'processing': 1, '.': 3, 'supports': 1, 'stop': 4, 'word': 2, 'removal': 1, ',': 2, 'you': 2, 'can': 2, 'find': 1, 'list': 2, 'words': 4, 'in': 2, 'corpus': 1, 'module': 1, 'to': 1, 'remove': 2, 'from': 1, 'a': 1, 'sentence': 1, 'divide': 1, 'your': 1, 'text': 1, 'into': 1, 'then': 1, 'if': 1, 'it': 1, 'exits': 1, 'provided': 1, 'by': 1}\n"
          ]
        }
      ]
    }
  ]
}